{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOaxQ/2rtvm9Xqhan5vzEWl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TheRealShamsaba/KnightVision/blob/main/KnightVisionNoteBook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSHwV_WPzvr-",
        "outputId": "7ff6efee-9098-4674-9de0-ad4c7bb7df95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-chess torch numpy psutil requests python-dotenv tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "INpKqHBc0936",
        "outputId": "43137759-e000-4b85-b34a-fef4e650832a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-chess\n",
            "  Downloading python_chess-1.999-py3-none-any.whl.metadata (776 bytes)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (5.9.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardx-2.6.4-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting chess<2,>=1 (from python-chess)\n",
            "  Downloading chess-1.11.2.tar.gz (6.1 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorboardX) (5.29.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading python_chess-1.999-py3-none-any.whl (1.4 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading tensorboardx-2.6.4-py3-none-any.whl (87 kB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: chess\n",
            "  Building wheel for chess (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chess: filename=chess-1.11.2-py3-none-any.whl size=147775 sha256=d9b8ebf060ab5eea07687713a1e66f5af696f96a49d14cd2f8cff3e88bde9bd5\n",
            "  Stored in directory: /root/.cache/pip/wheels/fb/5d/5c/59a62d8a695285e59ec9c1f66add6f8a9ac4152499a2be0113\n",
            "Successfully built chess\n",
            "Installing collected packages: tensorboardX, python-dotenv, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, chess, python-chess, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed chess-1.11.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 python-chess-1.999 python-dotenv-1.1.1 tensorboardX-2.6.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create KnightVision folder if it doesn't exist\n",
        "import os\n",
        "os.makedirs(\"/content/drive/MyDrive/KnightVision\", exist_ok=True)\n",
        "\n",
        "# Change into that folder\n",
        "os.chdir(\"/content/drive/MyDrive/KnightVision\")\n",
        "print(\"âœ… Now in:\", os.getcwd())\n",
        "\n",
        "# Clone your repo here\n",
        "!git clone https://github.com/TheRealShamsaba/basicChess.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zUe4kU953h_",
        "outputId": "cfbe7798-00e9-424f-8ecf-4e578e948ff6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Now in: /content/drive/MyDrive/KnightVision\n",
            "Cloning into 'basicChess'...\n",
            "remote: Enumerating objects: 1042, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 1042 (delta 45), reused 39 (delta 17), pack-reused 964 (from 2)\u001b[K\n",
            "Receiving objects: 100% (1042/1042), 53.99 MiB | 13.08 MiB/s, done.\n",
            "Resolving deltas: 100% (672/672), done.\n",
            "error: unable to create file .gitignore.gdoc: Operation not supported\n",
            "fatal: unable to checkout working tree\n",
            "warning: Clone succeeded, but checkout failed.\n",
            "You can inspect what was checked out with 'git status'\n",
            "and retry with 'git restore --source=HEAD :/'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt-get install -y stockfish"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsHnQNDD1ATk",
        "outputId": "2909e4f4-b9b4-4fdc-a8e3-c54fd8f94bd5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,628 B]\n",
            "\r            \rGet:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,801 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,067 kB]\n",
            "Get:12 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,040 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,741 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,587 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,561 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,254 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,350 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,750 kB]\n",
            "Fetched 32.5 MB in 5s (6,827 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Suggested packages:\n",
            "  polyglot xboard | scid\n",
            "The following NEW packages will be installed:\n",
            "  stockfish\n",
            "0 upgraded, 1 newly installed, 0 to remove and 36 not upgraded.\n",
            "Need to get 24.8 MB of archives.\n",
            "After this operation, 47.4 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 stockfish amd64 14.1-1 [24.8 MB]\n",
            "Fetched 24.8 MB in 3s (9,701 kB/s)\n",
            "Selecting previously unselected package stockfish.\n",
            "(Reading database ... 126308 files and directories currently installed.)\n",
            "Preparing to unpack .../stockfish_14.1-1_amd64.deb ...\n",
            "Unpacking stockfish (14.1-1) ...\n",
            "Setting up stockfish (14.1-1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!which stockfish\n"
      ],
      "metadata": {
        "id": "tUodjzb91DRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "print(\"Device count:\", torch.cuda.device_count())\n",
        "print(\"Current device:\", torch.cuda.current_device())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "461CGV--2LRq",
        "outputId": "f5612f6b-2b49-417c-d7bb-ac99d1c31200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: True\n",
            "Device count: 1\n",
            "Current device: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test StockFish"
      ],
      "metadata": {
        "id": "Ih3EbgPP1HRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import chess.engine\n",
        "os.environ[\"STOCKFISH_PATH\"] = \"/usr/games/stockfish\"\n",
        "engine = chess.engine.SimpleEngine.popen_uci(os.environ[\"STOCKFISH_PATH\"])\n",
        "print(\"âœ… Stockfish engine is running!\")\n",
        "engine.quit()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYaY1Rca1Gys",
        "outputId": "0fe22b40-4fc4-4f3d-fe3f-89917d088144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Stockfish engine is running!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs/"
      ],
      "metadata": {
        "id": "gn87X4R22il0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TELEGRAM_BOT_TOKEN'] = \"7763609017:AAHy0XmTNvRbHRhbDu3Btxixttdj6wRnV9I\"\n",
        "os.environ['TELEGRAM_CHAT_ID']  = \"5249977605\""
      ],
      "metadata": {
        "collapsed": true,
        "id": "jVBtzB2q2SAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"BASE_DIR\"] = \"/content/KnightVision\"\n",
        "os.environ[\"CHECKPOINT_DIR\"] = \"/content/KnightVision/checkpoints\"\n",
        "os.environ[\"RUNS_DIR\"] = \"/content/KnightVision/runs\"\n",
        "\n",
        "os.environ[\"NUM_SELFPLAY_GAMES\"] = \"10\"\n",
        "os.environ[\"MAX_MOVES\"] = \"200\"\n",
        "os.environ[\"SELFPLAY_WORKERS\"] = \"8\"\n",
        "os.environ[\"SELFPLAY_BATCH_SIZE\"] = \"16\"\n",
        "\n",
        "os.environ[\"DIR_NOISE_EPS\"] = \"0.25\"\n",
        "os.environ[\"DIR_NOISE_ALPHA\"] = \"0.3\"\n",
        "\n",
        "os.environ[\"PATIENCE\"] = \"10\"\n",
        "\n",
        "os.environ[\"REWARD_SHAPING_COEF\"] = \"1.0\"\n",
        "os.environ[\"ENTROPY_COEF\"] = \"0.01\"\n",
        "\n",
        "os.environ[\"SEED\"] = \"42\"\n",
        "\n",
        "os.environ[\"SELFPLAY_SEQ\"] = \"0\"\n",
        "os.environ[\"NUM_PGN_EPOCHS\"] = \"5\"\n",
        "\n",
        "os.environ[\"LOG_LEVEL\"] = \"INFO\"\n",
        "\n",
        "# ======== SET EPOCHS HERE ========\n",
        "epochs = 6  # Change this to however many you want to run overnight\n",
        "# =================================\n",
        "\n",
        "# Run train.py with argument\n",
        "!python /content/drive/MyDrive/KnightVision/basicChess/train.py --epochs {epochs}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3gLC-6rMtla",
        "outputId": "ad0356d3-e632-463e-bdde-327f4a76d167",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training script loaded...\n",
            "2025-06-30 14:10:09.439951: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751292609.460824   17465 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751292609.467149   17465 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-30 14:10:09.487751: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âœ… TensorFlow GPU memory growth enabled\n",
            "ğŸ†• Initializing new model and optimizer.\n",
            "âœ… Model initialized. Resuming at epoch 0\n",
            "ğŸ†• Initializing new model and optimizer.\n",
            "âœ… Model initialized\n",
            "âœ… ChessPGNDataset loaded: 2000000 samples found in /content/drive/MyDrive/KnightVision/data/games.jsonl\n",
            "âœ… Dataset instantiated: 2000000 samples\n",
            "âœ… Dataset ready\n",
            "âœ… Dataset split: 1800000 train, 200000 val samples\n",
            "âŒ Failed to send Telegram message: 404 Client Error: Not Found for url: https://api.telegram.org/bot.../sendMessage\n",
            "ğŸ”§ Training: epochs=6, batch_size=4096, pin_memory=True, num_workers=12\n",
            "/content/drive/MyDrive/KnightVision/basicChess/train.py:176: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n",
            "âœ… DataLoaders created: 1800000 train, 200000 val samples\n",
            "I0000 00:00:1751292616.038004   17465 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13720 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "Logging to: runs/chess_rl_v2\n",
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n",
            "Starting training...\n",
            "âŒ Failed to send Telegram message: 404 Client Error: Not Found for url: https://api.telegram.org/bot.../sendMessage\n",
            "âœ… Starting epoch loop...\n",
            "âŒ Failed to send Telegram message: 404 Client Error: Not Found for url: https://api.telegram.org/bot.../sendMessage\n",
            "âœ… Epoch 1: Using PGN dataset only (pre-training).\n",
            "ğŸ” Processing batch 1/440\n",
            "/content/drive/MyDrive/KnightVision/basicChess/train.py:65: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.cuda.amp.autocast():\n",
            "Epoch 1 | Batch 1/440 | Loss: 9.3492 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 2/440\n",
            "ğŸ” Processing batch 3/440\n",
            "ğŸ” Processing batch 4/440\n",
            "ğŸ” Processing batch 5/440\n",
            "ğŸ” Processing batch 6/440\n",
            "Epoch 1 | Batch 6/440 | Loss: 8.9426 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 7/440\n",
            "ğŸ” Processing batch 8/440\n",
            "ğŸ” Processing batch 9/440\n",
            "ğŸ” Processing batch 10/440\n",
            "ğŸ” Processing batch 11/440\n",
            "Epoch 1 | Batch 11/440 | Loss: 8.5740 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 12/440\n",
            "ğŸ” Processing batch 13/440\n",
            "ğŸ” Processing batch 14/440\n",
            "ğŸ” Processing batch 15/440\n",
            "ğŸ” Processing batch 16/440\n",
            "Epoch 1 | Batch 16/440 | Loss: 8.2634 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 17/440\n",
            "ğŸ” Processing batch 18/440\n",
            "ğŸ” Processing batch 19/440\n",
            "ğŸ” Processing batch 20/440\n",
            "ğŸ” Processing batch 21/440\n",
            "Epoch 1 | Batch 21/440 | Loss: 7.9903 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 22/440\n",
            "ğŸ” Processing batch 23/440\n",
            "ğŸ” Processing batch 24/440\n",
            "ğŸ” Processing batch 25/440\n",
            "ğŸ” Processing batch 26/440\n",
            "Epoch 1 | Batch 26/440 | Loss: 7.7721 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 27/440\n",
            "ğŸ” Processing batch 28/440\n",
            "ğŸ” Processing batch 29/440\n",
            "ğŸ” Processing batch 30/440\n",
            "ğŸ” Processing batch 31/440\n",
            "Epoch 1 | Batch 31/440 | Loss: 7.5819 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 32/440\n",
            "ğŸ” Processing batch 33/440\n",
            "ğŸ” Processing batch 34/440\n",
            "ğŸ” Processing batch 35/440\n",
            "ğŸ” Processing batch 36/440\n",
            "Epoch 1 | Batch 36/440 | Loss: 7.4932 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 37/440\n",
            "ğŸ” Processing batch 38/440\n",
            "ğŸ” Processing batch 39/440\n",
            "ğŸ” Processing batch 40/440\n",
            "ğŸ” Processing batch 41/440\n",
            "Epoch 1 | Batch 41/440 | Loss: 7.5272 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 42/440\n",
            "ğŸ” Processing batch 43/440\n",
            "ğŸ” Processing batch 44/440\n",
            "ğŸ” Processing batch 45/440\n",
            "ğŸ” Processing batch 46/440\n",
            "Epoch 1 | Batch 46/440 | Loss: 7.4501 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 47/440\n",
            "ğŸ” Processing batch 48/440\n",
            "ğŸ” Processing batch 49/440\n",
            "ğŸ” Processing batch 50/440\n",
            "ğŸ” Processing batch 51/440\n",
            "Epoch 1 | Batch 51/440 | Loss: 7.3818 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 52/440\n",
            "ğŸ” Processing batch 53/440\n",
            "ğŸ” Processing batch 54/440\n",
            "ğŸ” Processing batch 55/440\n",
            "ğŸ” Processing batch 56/440\n",
            "Epoch 1 | Batch 56/440 | Loss: 7.2967 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 57/440\n",
            "ğŸ” Processing batch 58/440\n",
            "ğŸ” Processing batch 59/440\n",
            "ğŸ” Processing batch 60/440\n",
            "ğŸ” Processing batch 61/440\n",
            "Epoch 1 | Batch 61/440 | Loss: 7.2561 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 62/440\n",
            "ğŸ” Processing batch 63/440\n",
            "ğŸ” Processing batch 64/440\n",
            "ğŸ” Processing batch 65/440\n",
            "ğŸ” Processing batch 66/440\n",
            "Epoch 1 | Batch 66/440 | Loss: 7.1726 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 67/440\n",
            "ğŸ” Processing batch 68/440\n",
            "ğŸ” Processing batch 69/440\n",
            "ğŸ” Processing batch 70/440\n",
            "ğŸ” Processing batch 71/440\n",
            "Epoch 1 | Batch 71/440 | Loss: 7.1453 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 72/440\n",
            "ğŸ” Processing batch 73/440\n",
            "ğŸ” Processing batch 74/440\n",
            "ğŸ” Processing batch 75/440\n",
            "ğŸ” Processing batch 76/440\n",
            "Epoch 1 | Batch 76/440 | Loss: 7.1612 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 77/440\n",
            "ğŸ” Processing batch 78/440\n",
            "ğŸ” Processing batch 79/440\n",
            "ğŸ” Processing batch 80/440\n",
            "ğŸ” Processing batch 81/440\n",
            "Epoch 1 | Batch 81/440 | Loss: 7.2162 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 82/440\n",
            "ğŸ” Processing batch 83/440\n",
            "ğŸ” Processing batch 84/440\n",
            "ğŸ” Processing batch 85/440\n",
            "ğŸ” Processing batch 86/440\n",
            "Epoch 1 | Batch 86/440 | Loss: 7.1116 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 87/440\n",
            "ğŸ” Processing batch 88/440\n",
            "ğŸ” Processing batch 89/440\n",
            "ğŸ” Processing batch 90/440\n",
            "ğŸ” Processing batch 91/440\n",
            "Epoch 1 | Batch 91/440 | Loss: 7.1041 | GPU Mem: 604.3MB\n",
            "ğŸ” Processing batch 92/440\n",
            "ğŸ” Processing batch 93/440\n",
            "ğŸ” Processing batch 94/440\n",
            "ğŸ” Processing batch 95/440\n",
            "ğŸ” Processing batch 96/440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/drive/MyDrive/KnightVision/basicChess/train.py --epochs 10"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1adHV2bTJ2mp",
        "outputId": "f3cbb317-87b0-4365-a7d6-bb3ab2af9925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training script loaded...\n",
            "2025-06-30 09:39:47.248829: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1751276387.268782   12501 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1751276387.275186   12501 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-06-30 09:39:47.296495: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "âœ… TensorFlow GPU memory growth enabled\n",
            "ğŸ†• Initializing new model and optimizer.\n",
            "âœ… Model initialized. Resuming at epoch 0\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/KnightVision/basicChess/train.py\", line 525, in <module>\n",
            "    model, optimizer, start_epoch = load_or_initialize_model(\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/drive/MyDrive/KnightVision/basicChess/model_utils.py\", line 18, in load_or_initialize_model\n",
            "    model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 2581, in load_state_dict\n",
            "    raise RuntimeError(\n",
            "RuntimeError: Error(s) in loading state_dict for ChessNet:\n",
            "\tMissing key(s) in state_dict: \"res_blocks.0.conv1.weight\", \"res_blocks.0.conv1.bias\", \"res_blocks.0.bn1.weight\", \"res_blocks.0.bn1.bias\", \"res_blocks.0.bn1.running_mean\", \"res_blocks.0.bn1.running_var\", \"res_blocks.0.conv2.weight\", \"res_blocks.0.conv2.bias\", \"res_blocks.0.bn2.weight\", \"res_blocks.0.bn2.bias\", \"res_blocks.0.bn2.running_mean\", \"res_blocks.0.bn2.running_var\", \"res_blocks.1.conv1.weight\", \"res_blocks.1.conv1.bias\", \"res_blocks.1.bn1.weight\", \"res_blocks.1.bn1.bias\", \"res_blocks.1.bn1.running_mean\", \"res_blocks.1.bn1.running_var\", \"res_blocks.1.conv2.weight\", \"res_blocks.1.conv2.bias\", \"res_blocks.1.bn2.weight\", \"res_blocks.1.bn2.bias\", \"res_blocks.1.bn2.running_mean\", \"res_blocks.1.bn2.running_var\", \"res_blocks.2.conv1.weight\", \"res_blocks.2.conv1.bias\", \"res_blocks.2.bn1.weight\", \"res_blocks.2.bn1.bias\", \"res_blocks.2.bn1.running_mean\", \"res_blocks.2.bn1.running_var\", \"res_blocks.2.conv2.weight\", \"res_blocks.2.conv2.bias\", \"res_blocks.2.bn2.weight\", \"res_blocks.2.bn2.bias\", \"res_blocks.2.bn2.running_mean\", \"res_blocks.2.bn2.running_var\", \"res_blocks.3.conv1.weight\", \"res_blocks.3.conv1.bias\", \"res_blocks.3.bn1.weight\", \"res_blocks.3.bn1.bias\", \"res_blocks.3.bn1.running_mean\", \"res_blocks.3.bn1.running_var\", \"res_blocks.3.conv2.weight\", \"res_blocks.3.conv2.bias\", \"res_blocks.3.bn2.weight\", \"res_blocks.3.bn2.bias\", \"res_blocks.3.bn2.running_mean\", \"res_blocks.3.bn2.running_var\", \"res_blocks.4.conv1.weight\", \"res_blocks.4.conv1.bias\", \"res_blocks.4.bn1.weight\", \"res_blocks.4.bn1.bias\", \"res_blocks.4.bn1.running_mean\", \"res_blocks.4.bn1.running_var\", \"res_blocks.4.conv2.weight\", \"res_blocks.4.conv2.bias\", \"res_blocks.4.bn2.weight\", \"res_blocks.4.bn2.bias\", \"res_blocks.4.bn2.running_mean\", \"res_blocks.4.bn2.running_var\". \n",
            "\tUnexpected key(s) in state_dict: \"res_blocks.0.0.weight\", \"res_blocks.0.0.bias\", \"res_blocks.0.1.weight\", \"res_blocks.0.1.bias\", \"res_blocks.0.1.running_mean\", \"res_blocks.0.1.running_var\", \"res_blocks.0.1.num_batches_tracked\", \"res_blocks.0.3.weight\", \"res_blocks.0.3.bias\", \"res_blocks.0.4.weight\", \"res_blocks.0.4.bias\", \"res_blocks.0.4.running_mean\", \"res_blocks.0.4.running_var\", \"res_blocks.0.4.num_batches_tracked\", \"res_blocks.1.0.weight\", \"res_blocks.1.0.bias\", \"res_blocks.1.1.weight\", \"res_blocks.1.1.bias\", \"res_blocks.1.1.running_mean\", \"res_blocks.1.1.running_var\", \"res_blocks.1.1.num_batches_tracked\", \"res_blocks.1.3.weight\", \"res_blocks.1.3.bias\", \"res_blocks.1.4.weight\", \"res_blocks.1.4.bias\", \"res_blocks.1.4.running_mean\", \"res_blocks.1.4.running_var\", \"res_blocks.1.4.num_batches_tracked\", \"res_blocks.2.0.weight\", \"res_blocks.2.0.bias\", \"res_blocks.2.1.weight\", \"res_blocks.2.1.bias\", \"res_blocks.2.1.running_mean\", \"res_blocks.2.1.running_var\", \"res_blocks.2.1.num_batches_tracked\", \"res_blocks.2.3.weight\", \"res_blocks.2.3.bias\", \"res_blocks.2.4.weight\", \"res_blocks.2.4.bias\", \"res_blocks.2.4.running_mean\", \"res_blocks.2.4.running_var\", \"res_blocks.2.4.num_batches_tracked\", \"res_blocks.3.0.weight\", \"res_blocks.3.0.bias\", \"res_blocks.3.1.weight\", \"res_blocks.3.1.bias\", \"res_blocks.3.1.running_mean\", \"res_blocks.3.1.running_var\", \"res_blocks.3.1.num_batches_tracked\", \"res_blocks.3.3.weight\", \"res_blocks.3.3.bias\", \"res_blocks.3.4.weight\", \"res_blocks.3.4.bias\", \"res_blocks.3.4.running_mean\", \"res_blocks.3.4.running_var\", \"res_blocks.3.4.num_batches_tracked\", \"res_blocks.4.0.weight\", \"res_blocks.4.0.bias\", \"res_blocks.4.1.weight\", \"res_blocks.4.1.bias\", \"res_blocks.4.1.running_mean\", \"res_blocks.4.1.running_var\", \"res_blocks.4.1.num_batches_tracked\", \"res_blocks.4.3.weight\", \"res_blocks.4.3.bias\", \"res_blocks.4.4.weight\", \"res_blocks.4.4.bias\", \"res_blocks.4.4.running_mean\", \"res_blocks.4.4.running_var\", \"res_blocks.4.4.num_batches_tracked\". \n"
          ]
        }
      ]
    }
  ]
}